- the idea is basically the same as with PDES1, that we try to provide a lookahead.
- But instead of doing it on road level, we do it on zone levels.


- each road needs to be assigned to a zone (based on its location => two passes of road files needed)
- a link can only belong to one zone at a time

- At the beginning: Initialize Zones.
     - This means: All roads which (potentially could) flow into different zones, must periodically schedule self/null messages.
     - This enables each zone to start
     
- The message queue of a zone can only be processed, if
              - a message has arrived from all incoming links to the zone
              - and only those messages can be processed, with a time stamp smaller than the time stamp of the smallest message
                from any incoming link
                
                
- a zone can be assigned to any executor thread. This means there can be more zones than processes. Any zones, which can progress
is just processed. Making more zones than threads/processors probably also leads to less waiting on locks? But on the other hand
it leads to more border links (really?).

- the look ahead increases in a certain way with many zones: normally there is a small look ahead for a big region (containing lots of potential events).
  But with smaller zones, the proportion between lookahead and zones size becomes smaller, so that ???? Is this true?
  
- We can make lots of message queues (one for each zone). Each MessageExcutor can then just do TryLocks and if not successful,
  just continue with the next zone.
  
- Simple divisions of zones at the beginning: Make them vertical. For example find out the x min and x max and then
  make equi-distant zones e.g. 10. and then get started the MessageExecutors to process them.
  
 => find out, if y direction is better than x direction.

- This approach will allow to progress empty zones quickly

- There will always be messages in the system, because of the null messages. So we have to set a maximum time
  for the simulation. As soon as the simulation is empty of real messages, the simulation will get ahead much
  faster anyway.
 
- THINK ABOUT IT:
    - Do we really need the new infrastructure of PDES1 with the EnterRequestMessage etc. Because we could also do it without or not?
    by directly 
    
    - does the inner road have an effect into the same junction, so that it could be processed to late or early? think about
    that also when doing implementation, that we get that also right...
    - 

Splitting the map:
 - (done) splitting the map in parts of same size can be very bad, if all most events happen in
   the same area.
 - (done) we could do the following: Make 1000 equidistant buckets of the map (e.g. x direction). Then look at the plan
   and find out, how many events will happen in which bucket. And then try to make only numberOfExecutorThread buckets
   from the 1000 equidistant buckets, by having the same number of events in each bucket.
   => This process can be accellarated by choosing random persons and their plans and put those events into the buckets.
   




- Problems:
    - it is possible, that in ZoneMessageQueue.getNextMessage the message queue is empty, even though
      the condition, that there are enough messages to process the queue condition is fullfilled
       => this leads to a null pointer exception there...
    - es gibt zu viele messages (ca. 3 mal mehr als anwendungs messages). Kann man das irgendwie 
      runterbringen?
      => vorallem das scheduling ist ein problem, weil es lockings braucht
      	- lösung 1: don't send any message to a node, if we just sent him a real message (sehr kleiner gain)
      	- lösung 2: try building bigger look aheads
        - lösung 3: (implemented): don't schedule the ZoneBorderMessages (because they actually do nothing) => implemented.
        - lösung 4: (implemented): make numberOfQueuedMessages more concurrent
            => more possible... 
    - main problem: incrementNumberOfQueuedMessages => concurrentHashMap mit ConcurrentMap.replace benutzt.
    - bad idea: don't send any border message, if there is a car on the road, but only set a timer
    	=> the getNextMessage would not function anymore...
    - next idea: warn a outBorder road, that traffic is coming. only registered roads should be informed
    	-> need to find a balance: too large areas for look ahead are fragil, too small provide small look ahead
    	=> start with look ahead of one or two roads
    	=> try resetting look ahead, when roads are empty again
    	 
    - wir haben zu viele timer messages zum schedulen
    
- TODO: 
     - performance verbessern
        - putMessage should be possible quickly (use my cuncurrent list implementation) => auch möglich mit nur 
        - wieso dauert getNextMessage so lang (obwohl empty buffers fast überhaupt nicht dauert).
        - getThreadId in MessageExecutor (ThreadLocal), dauert ca. 5.8sec zum ausführen
            => man könnte es der message mitgeben, etc...
        - empty buffer takes longer, than one would think...   
        - unix xwindow aus probieren
        - auch in normaler DES bzw. erster PDES version das Priority queue problem lösen
        - => grosse tests ausprobieren
        
        NEXT: 
        - implemented: such out border roads, which have no timer scheduled (because no car drives over them)
           => do static look ahead at the beginning and schedule all timers. In between do normal timers.
              - for such outborder messages, which will have no car on them during the whole simulation, they
              should send border message for time double.max and then do nothing.
           => resolve problem: perhaps too few events (test 8)
           => think again about the whole procedure, if everything is alright
             - hatte pracktisch einen deadlock auf satwal (wie konnte das passieren?)
           - perhaps use treeSet instead of PriorityQueue, because of the missing implementation of remove  
           - try out bigger input files (e.g. 10% planes).
           - should I make messagesArrivedFromRoads in ZoneMessageQueue volatile?
           
           - test, if logic of multi processor variant is the same as single cpu
        
           - problem: single cpu variante produziert zu wenig events bei test1 (test12 ok)
           
           - make tests and also consider the event count to be part of it
           
           - ich muss rausfinden, ob ein speed up stattfindet
           
           
           - next step: eher später profilen beginnen, eher probieren jetztige version zu sichern,
             dass alles ok.
   
              
              => next problem/suspicion: is there any deviation between the events, if we use
              different number of processors => do check this
              => reason: it was found out, that some simulation have longer durations than others...
                 (but there is hope, that this is just a wrong alarm, because of some reasons
                 I may think of at the moment).
           
           
           - es gibt ein exception beim iterieren, wie unterdrückt man dieses?
           
           
           - use different constructor for events => objects instead of ids
               => that is more efficient
           
      - vorallem für grosse simulationen mit vielen agenten lohnt sich unsere simulation wahrscheinlich eher, weil dann
      sind viele agenten im gleichen area und die bordermessages werden nicht geschickt, weil diese durch normale messages
      ersetzt werden. => try input 7M
      
     
        
      - problem: test 1 creates too litte messages after having introduced the is killMessage instead of remove from Message queue  
        => the other tests run ok..., when using one thread version
        
      - die parallelizierung wird nicht genug ausgenützt? bzw. soll ich grössere scenarien ausprobieren um rauszufinden,
      wieviel es genützt hat? bzw. profiling machen?
      
      => continue with test 15...
      
      - man könnte before man lange runs macht, einen benchmark vorschalten, der den split der karte gut macht
        für die gegebene anzahl processoren oder adaptiv: man verschiebe grenzen so, wie man denkt vom letzten run her
      
      
      
     
VERY IMPORTANT TODOS:
      - code aufräumen, code kopieren in core, tests schreiben für code
 		=> test z.b. für einen agenten (eqil net)
      - act start und act end noch machen. Alle personen machen einen act start um 0:00.
      - enter link am schluss vom leg werfen (gleiche zeit wie end leg), aber vor dem end leg event werfen
      - anstatt erstes enter link, ein wait2link event werfen am anfang.
      - Need to compare iterations of MobSim, DeqSim, JavaDESSim
      - run 600 sample
      
      
      - der einzige big bottleneck in concurrent version ist, dass bufferEvent. Deshalb sollte ich das auch noch voll parallelizieren.
        Dann haben alle events freien lauf und das erklärt auch das schlimmer werden, wenn man mehr threads benutzt
        und das opimum bei 6 threads.
       => push idee: jeder thread hat seine events list. Diese füllt er auf. Sobald er z.B. 100000 events hat, übergibt er 
        diese an den main thread, wo es für jeden thread eine queue hat. Dadruch muss nur jeden 100000 event pro Thread ein
        lock geschehen, anstatt fast jeden event wie bisher.
      
      - muss Sachen von home nach data/matsim/wrashid verschieben auf satawal!!!!
       => speicher nur dort brauchen
      	=> immer sandbox dort machen...
      - beim deqsim: grünzeiten simu nicht verwenden
      - im deqsim config file: numerofthreads gleich anzahl cpus setzen
      - is event order for event process important (e.g. for computing scoring...)
      
      - vergleich mit counts: jede 10-te iteration:
        "countsScaleFactor" im config.txt => if 10% sample, then value ist 10 (not 0.1)!
        output jede 10-te iteration, lässt uns grafisch und textual vergleiche machen => unbedingt machen.
         
- Done:
     -  perhaps move arround the zone separators to achieve better lookahead propoerties? 
     -  perhaps doch several vertical Splits machen: dann können teile der Karte weiterarbeiten,
             anstatt, dass man von der anderen Seite abhängig ist.
             => Gegenargument: Man muss auf die andere Seite sowieso warten.
     - problem lösung: timer message muss höhere priorität bekommen als border message (mit gleichem time stamp),
      sonst bleibt message queue einfach stehen, weil keine neuen messages mehr produziert werden
     - MessageFactory updated to support full concurreny for each zone   
     - zone sizing is not equal yet => now each link is considered as a wait for each zone
     - getSimtime consumes around 15%+ of the CPU time => solved by removing ThreadLocal variable simTime in MessageExecutor
     - message counter removed, because it is a common synchronization point
   
     
     
     ===================================================
     - (solved) leave road, getFirst problem occured on satawal...
       => perhaps I am scheduling the message in the wrong messageQueue, because the original deadlock prevention message
          perhaps is already applied in the previous scheduler?
       => do we have a race condition between Deadlock prevention message and enterRequestMessage ? 
 		=> Fact: two times leave is done on a road (a Deadlock prevention message, which should have been timed out, was still alive)
 		=> the problem is not my problem, but rather that of java api: http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6207984
 		   - use queue.removeAll(Collections.singletonList(o)) instead of queue.remove for priority queues.
     =======================================================
     - when trying to replace lock by a hashmap class, there is some problem, that a message is missing for 
      some reason (not found out yet).
      - the problem was, that the read and write operation for messagesArrivedFromRoads needs to be outside  
     =======================================================
     - urgent: jetzt passiert heap space problem auch mit test 12 => das ist ein sehr kleiner test,
             d.h. sollte das eigentlich nicht passieren. => search the leak... => gelöst
     ==========================================================
     - find out, why there are less events using the new lookahead approach
           - wieso hat es soviele Messages (viel mehr als events), weil das sollte nicht mehr so sein.
           => es scheint, dass der split nicht perfekt ist... => zuviele events in einem bereich
     ==============================
       - man bleibt stecken bei 13 CPU version auf satwal => im debug mode nicht,
           aber im normalen mode schon????
              => 13 cpu => 2 zones hatten ein message zu wenig erhalten und konnten deshalb nicht weiterfahren
              => es gibt 1 message zu wenig be den zonen aus irgend einen grund
              => Lösung: es hat mit dem remove der message zu tun ( m!= null) in getNextMessage. Das problem muss behoben werden.
     =================================        
      - es kommen zu wenig events
           => max simulation time war zu niedrig eingestellt
     =====================================       
             - es gib zu wenig events... bei einigen simulationen...
              => count different events to find out, which messages are missing...
              => lösung: maxSimulationLength war falsch eingestellt
      ======================================        
      - priotiy queue in PDES => erstzen der operation...
      New class: DebuggedPriorityQueue implemented
     ========================================
     ExceptionInInitializerError in JavaPDEQSim2
     => Simulation of Simulationparameters not successful
     => static class konnte nicht initializiert werden, weil ich number of threads falsch gesetzt hatte
     =======================================
      - alle zones sollten gelich viele messages beinhalten. Momentan haben wir bei 12 cpu starke variationen: ein cpu hat 6M messages, ein anderer 2M.
      => Vermutung/Bzw. fast sicher: Ob ein run mit x cpus schneller ist als ein run mit y CPUs, gegeben x>y, hängt davon ab, was die maximale Anzahl
         events pro zone ist. Gegebenfalls könnten y CPUs schneller sein, wenn sie events gleich verteilen.
         => ich muss das genauer analysieren, bzw. gleichverteilung anstreben.
         => die vermutung ist nicht ganz sicher (habe gegenbeispiele gesehen: obwohl x>y und maxevent(x)<maxevent(y), trotzdem y CPU schneller.
         => profilen gegebenenfalls.
         => könnte es mit speicher zu tun haben?
         => momentan ist es so, dass anzahl events stark unterschiedlich ist auf strassen => das erklärt den unterschied,
            aber wie kann dass passieren? Haben wir falsche zone zugewiesen oder?
            => habe unterschied gefunden: 
            In JavaPDEQSim2: SimulationParameters.zoneBorderLines[i]=bucketBoundries[bucketCounter];
            ersteztt durch: SimulationParameters.zoneBorderLines[i]=bucketBoundries[bucketCounter-1];
      ===================================================      
           - facilites auch laden, wenn ich genug speicher habe
        -> braucht ca. 9gb ram
     =======================================================
        -es dauert ca. 6min um 1M plans einzulesen auf Satawal
     =========================================================
        exact event numbers (DEQSim2: test6: 7665182, test12: 1817160)
     
     
     
     
     
     
Experiments and Results
=========================
Ex1
----
network used: "VISUM export national network 2007-11-28"
300K agents (arround 21.4M Events) => Satawal.
Time of descret event simulation part only considered.
MobSim: 2160 sec. (events: wahrschein 21M) 
PDES, 1 CPU: 660 sec. => komisch, hält am schluss nicht an, wieso????? => wiederholen
PDES2, 1 CPU: 300  sec. 
PDES2, 3 CPU:  224 sec.
PDES2, 6 CPU:  128/168 sec. 
PDES2, 9 CPU:  115/155 sec. (only simulation/simulation with initialization)
PDES2, 12 CPU: 138/182 sec. 




Ex2:
----
network used: "VISUM export national network 2007-11-28"
67K agents (arround 7.66M events)  => Satawal.
Time of descret event simulation part only considered.
MobSim: 1260 sec
PDES, 1 CPU: 108 sec 
PDES2, 1 CPU: 113.8 sec 
PDES2, 6 CPU: 38.8 sec 
PDES2, 12 CPU: 29.3 sec

Ex3:
----
615K agents (only MIV, most located in Zurich area - Westumfahrung), arround 55.8M events, run on Satawal
network used: "VISUM export national network 2007-11-28" 
ram used: less than 5gb (without facilities, which are more than 9gb at least!!!)
facilities were disabled, because else more ram were required, than were at my disposal of this experiment.
(census2000_dilZh30km_miv used)
folder: input_615K
time for one iteration taken.

MobSim: 52Min
PDES2, 1 CPU: 732/846
PDES2, 3 CPU: 539/664
PDES2, 6 CPU: 240/356
PDES2, 9 CPU: 358/474 => why slower => perphas, because machine not fully free?
PDES2, 12 CPU: 301/412 sec. => not all the time 12 cpus were availabe, because of this the test must be repated later


Ex4:
----
2.28M agents (census2000_miv (2.3 Mio, whole CH)), arround 153.6M events, run on Satawal
network: whole switzerland
network: has 60492 links, 40000 in CH, 10000 in Zürich area.
- beim vertical cut gibt es immer ca. 200 incoming links into zones. nur die 
randzonen auf beiden seiten haben ca. 100.
- 21gb with facilities, arround 12gb without facilities.

PDES2, 12 CPU: 877/1273 sec.
=> attention: profiling run deliverd 150.5M events, some thing is wrong here...
=> could it have to do something with max simulation length???
=> könnte es damit zu tun haben, dass time stamp in falscher reihenfolge reinkommen beim processEvent und er diese
   ignoriert???



     